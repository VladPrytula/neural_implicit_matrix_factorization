{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_FOLDER = Path(\"../data/raw/\")\n",
    "PROCESSED_DATA_FOLDER = Path(\"../data/processed/\")\n",
    "\n",
    "spain_sales_raw = RAW_DATA_FOLDER / \"spanish_sales.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RATINGS = 4\n",
    "USER_COLUMN = 'userId'\n",
    "ITEM_COLUMN = 'itemId'\n",
    "VALID_NEGATIVE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv(spain_sales_raw, parse_dates=True,dtype={\"customer_id\": int, \"product_id\": int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df['rating'] = 1.0\n",
    "sales_df.date = pd.to_datetime(sales_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df.rename(columns={'customer_id':'uid',\n",
    "                          'product_id':'mid',\n",
    "                          'date':'timestamp'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Filtering out users with less than 4 ratings\n",
      "INFO:__main__:Mapping original user and item IDs to new sequential IDs\n",
      "INFO:__main__:Range of userId is [0, 204100]\n",
      "INFO:__main__:Range of itemId is [0, 6112]\n",
      "INFO:__main__:num_users is 204101, num_items is 6113\n"
     ]
    }
   ],
   "source": [
    "sales_df = pd.read_csv(spain_sales_raw, parse_dates=True,dtype={\"customer_id\": int, \"product_id\": int})\n",
    "sales_df['ratings'] = 1.0\n",
    "sales_df.date = pd.to_datetime(sales_df.date)\n",
    "sales_df.rename(columns={'customer_id':'uid',\n",
    "                      'product_id':'mid',\n",
    "                      'date':'timestamp'}, \n",
    "             inplace=True)\n",
    "df = sales_df.copy()\n",
    "\n",
    "# first let us filter out the users with less than MIN_RATINGS interations\n",
    "logger.info(\n",
    "    \"Filtering out users with less than {} ratings\".format(MIN_RATINGS))\n",
    "grouped = df.groupby('uid')\n",
    "df = grouped.filter(lambda x: len(x) >= MIN_RATINGS).copy()\n",
    "\n",
    "# now let us factoriyze (re-index users)\n",
    "logger.info(\"Mapping original user and item IDs to new sequential IDs\")\n",
    "df['userId'] = pd.factorize(df['uid'])[0]\n",
    "df['itemId'] = pd.factorize(df['mid'])[0]\n",
    "\n",
    "# Need to sort before popping to get last item\n",
    "df.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "logger.info('Range of userId is [{}, {}]'.format(\n",
    "    df.userId.min(), df.userId.max()))\n",
    "logger.info('Range of itemId is [{}, {}]'.format(\n",
    "    df.userId.min(), df.itemId.max()))\n",
    "\n",
    "num_users = len(df['userId'].unique())\n",
    "num_items = len(df['itemId'].unique())\n",
    "logger.info(\"num_users is {}, num_items is {}\".format(\n",
    "    num_users, num_items))\n",
    "\n",
    "# clean up data\n",
    "del df['ratings'], df['timestamp']\n",
    "df = df.drop_duplicates()  # assuming it keeps order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have filtered and sorted by time data, we can split test data out\n",
    "grouped_sorted = df.groupby(USER_COLUMN, group_keys=False)\n",
    "test_data = grouped_sorted.tail(1).sort_values(by=USER_COLUMN)\n",
    "# need to pop for each group\n",
    "train_data = grouped_sorted.apply(lambda x: x.iloc[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: no way to keep reference training data ordering because use of python set and multi-process\n",
    "# It should not matter since it will be later randomized again\n",
    "# save train and val data that is fixed.\n",
    "train_ratings = torch.from_numpy(train_data.values)\n",
    "torch.save(train_ratings, PROCESSED_DATA_FOLDER/'train_ratings.pt')\n",
    "test_ratings = torch.from_numpy(test_data.values)\n",
    "torch.save(test_ratings, PROCESSED_DATA_FOLDER/'test_ratings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the difficult part:\n",
    "we have to sample negatives in a memory efficient way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TestNegSampler:\n",
    "    def __init__(self, train_ratings, nb_neg):\n",
    "        self.nb_neg = nb_neg\n",
    "        self.nb_users = int(train_ratings[:, 0].max()) + 1\n",
    "        self.nb_items = int(train_ratings[:, 1].max()) + 1\n",
    "\n",
    "        # compute unique ids for quickly created hash set and fast lookup\n",
    "        ids = (train_ratings[:, 0] * self.nb_items) + train_ratings[:, 1]\n",
    "        self.set = set(ids)\n",
    "\n",
    "    def generate(self, batch_size=128*1024):\n",
    "        users = torch.arange(0, self.nb_users).reshape(\n",
    "            [1, -1]).repeat([self.nb_neg, 1]).transpose(0, 1).reshape(-1)\n",
    "\n",
    "        items = [-1] * len(users)\n",
    "\n",
    "        random_items = torch.LongTensor(\n",
    "            batch_size).random_(0, self.nb_items).tolist()\n",
    "        print('Generating validation negatives...')\n",
    "        for idx, u in enumerate(tqdm.tqdm(users.tolist())):\n",
    "            if not random_items:\n",
    "                random_items = torch.LongTensor(\n",
    "                    batch_size).random_(0, self.nb_items).tolist()\n",
    "            j = random_items.pop()\n",
    "            while u * self.nb_items + j in self.set:\n",
    "                if not random_items:\n",
    "                    random_items = torch.LongTensor(\n",
    "                        batch_size).random_(0, self.nb_items).tolist()\n",
    "                j = random_items.pop()\n",
    "\n",
    "            items[idx] = j\n",
    "        items = torch.LongTensor(items)\n",
    "        return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 133032/273283150 [00:00<03:25, 1330318.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating validation negatives...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273283150/273283150 [03:04<00:00, 1484856.44it/s]\n"
     ]
    }
   ],
   "source": [
    "sampler = _TestNegSampler(train_ratings.cpu().numpy(), VALID_NEGATIVE)\n",
    "test_negs = sampler.generate().cuda()\n",
    "test_negs = test_negs.reshape(-1, VALID_NEGATIVE)\n",
    "torch.save(test_negs, PROCESSED_DATA_FOLDER/'/test_negatives.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1673629, 4])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([204101, 4])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27328315, 10])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_negs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
